{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s를 split을 통해서 하나씩 tokenize를 시켜준다. 그러면 t가 나올 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'man', 'in', 'the', 'house']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk에 포함된 Text를 쓰면 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.split 대신에 t를 써도 괜춘\n",
    "b = nltk.Test(s.split())\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.Text(s.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os에서 현재 디렉토리에 포함되어있는 06_01.txt를 열어준다.\n",
    "os부터 txt까지는 full path이라고 생각\n",
    "그 파일을 utf8로 encoding이 되어있으니 encoding을 맞게 하고 (이걸 안 하면 한글이 깨진다) \n",
    "read == 열어라\n",
    "raw에 텍스트 파일이 담겨져 있을 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a78b1fb2bab9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타입 / 길이 / 텍스트의 75번째 character (word 아님)까지 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk에 tokenize이라는 함수가 있다. split보다 세련된 함수. 입력은 raw string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "257726\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text 함수\n",
    "type이 nltk 전용 variable로 만들어졌다. \n",
    "nltk 속에 포함된 다양한 함수를 사용할 수 있어서 nltk 전용 variable로 만들어주면 좋다.\n",
    "collocations 함수 : 자주 반복이 되는, pair로 나오는 단어를 파악. 이름도 있구 young man도 있음.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concordance 함수 \n",
    "<br>\n",
    "concordance('해당단어', 숫자1, 숫자2) ; 해당단어를 중심으로 양쪽으로 총 79개의 character를 보고 25개의 line을 준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 162 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great', 79, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk라는 library는 함수뿐만 아니라 data를 갖도 놓기도 한다. nltk안에 melville-moby_dick.txt가 들어가 있는데 그걸 불러오는 것이다. \n",
    "raw에 텍스트 스트링이 들어온다. \n",
    "FreqDist - 빈번도를 알려준다.\n",
    "most_common - raw string만 있어도 그 안에서 어떤 것이 가장 빈번하게 나오는지 알려준다. 여기서는 상위 50개를 알려준다. \n",
    "\n",
    "\n",
    "[ch.lower() for ch in raw if ch.isalpha()]\n",
    "raw 속에서 (in raw) ch 가 들어가는데 for loop 아래에 ch가 알파벳이면 (ch.isalpha) 그것을 lowercase시켜서 list를 만들어라.\n",
    "raw가 1000개가 있으면 ch가 for loop에 1000번 돌아간다. ch에 차례대로 들어간다고 생각. 즉, 문장 부호가 제외하고 대문자도 소문자화시켜서 list로 만들고 싶은 것임. \n",
    "\n",
    "most common 상위 5개로 함. \n",
    "상위 5개한 것에서 most common이 주는 것이 list안에 tuple이 있음. 지금 char와 count가 두 개자나. for loop 두 개가 도는 것이다. \n",
    "[char for (char, count) in fdist.most_common(5)]\n",
    "상위 5개 [('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)] <- 이것에서 ('e', 117092) 이것만 보면 e와 117092가 동시에 for loop 두 개가 5번 돌아서 Out가 나오는 것임.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338)]\n",
      "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "print(raw[:200])\n",
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(5))\n",
    "\n",
    "\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "[char for (char, count) in fdist.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
